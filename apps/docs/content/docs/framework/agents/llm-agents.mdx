---
title: LLM Agents
description: Use language models for reasoning, decision-making, and tool usage
---

import { Cards, Card } from "fumadocs-ui/components/card";
import { Callout } from "fumadocs-ui/components/callout";

LLM agents are the most commonly used agent type in ADK-TS. They leverage Large Language Models (LLMs) for reasoning, understanding natural language, making decisions, and interacting with tools to accomplish complex tasks.

Unlike deterministic workflow agents that follow predefined paths, LLM agents are dynamic and context-aware. They interpret instructions, analyze situations, and decide how to proceed - whether that's using tools, transferring control to other agents, or generating responses directly.

## Configuration Options

All LLM agent configuration options and their requirements:

| Option                     | Required | Type                                 | Description                                          |
| -------------------------- | -------- | ------------------------------------ | ---------------------------------------------------- |
| `name`                     | âœ…       | `string`                             | Unique identifier for the agent                      |
| `description`              | âŒ       | `string`                             | Brief description of agent capabilities              |
| `model`                    | âŒ\*     | `string \| BaseLlm \| LanguageModel` | LLM model to use (\*inherits from parent if not set) |
| `instruction`              | âŒ       | `string \| InstructionProvider`      | Primary behavior instructions                        |
| `globalInstruction`        | âŒ       | `string \| InstructionProvider`      | Global instructions for entire agent tree            |
| `tools`                    | âŒ       | `ToolUnion[]`                        | Available tools for the agent                        |
| `subAgents`                | âŒ       | `BaseAgent[]`                        | Sub-agents for delegation                            |
| `codeExecutor`             | âŒ       | `BaseCodeExecutor`                   | Code execution capability                            |
| `planner`                  | âŒ       | `BasePlanner`                        | Planning and reasoning strategy                      |
| `memoryService`            | âŒ       | `BaseMemoryService`                  | Long-term memory storage                             |
| `sessionService`           | âŒ       | `BaseSessionService`                 | Conversation management                              |
| `artifactService`          | âŒ       | `BaseArtifactService`                | File storage and management                          |
| `includeContents`          | âŒ       | `"default" \| "none"`                | Context inclusion behavior                           |
| `outputKey`                | âŒ       | `string`                             | Session state key for agent output                   |
| `inputSchema`              | âŒ       | `ZodSchema`                          | Input validation schema                              |
| `outputSchema`             | âŒ       | `ZodSchema`                          | Output validation schema                             |
| `generateContentConfig`    | âŒ       | `GenerateContentConfig`              | LLM generation parameters                            |
| `disallowTransferToParent` | âŒ       | `boolean`                            | Disable parent agent transfers                       |
| `disallowTransferToPeers`  | âŒ       | `boolean`                            | Disable peer agent transfers                         |
| `userId`                   | âŒ       | `string`                             | User identifier for sessions                         |
| `appName`                  | âŒ       | `string`                             | Application identifier                               |
| `beforeAgentCallback`      | âŒ       | `BeforeAgentCallback`                | Pre-execution hooks                                  |
| `afterAgentCallback`       | âŒ       | `AfterAgentCallback`                 | Post-execution hooks                                 |
| `beforeModelCallback`      | âŒ       | `BeforeModelCallback`                | Pre-LLM call hooks                                   |
| `afterModelCallback`       | âŒ       | `AfterModelCallback`                 | Post-LLM call hooks                                  |
| `beforeToolCallback`       | âŒ       | `BeforeToolCallback`                 | Pre-tool execution hooks                             |
| `afterToolCallback`        | âŒ       | `AfterToolCallback`                  | Post-tool execution hooks                            |

## Configuration Details

### name (Required)

**Type:** `string`

Unique identifier for the agent. Must be a valid identifier (start with letter/underscore, contain only letters, numbers, underscore). Critical for multi-agent systems where agents delegate tasks.

```ts
const agent = new LlmAgent({
  name: "customer_support_agent", // âœ… Valid
  // name: "user", // âŒ Reserved keyword
  // name: "123agent", // âŒ Cannot start with number
});
```

### description

**Type:** `string` | **Default:** `""`

Brief description of the agent's capabilities. Used by other agents for routing decisions in multi-agent systems. Should be specific enough to differentiate from peer agents.

```ts
const agent = new LlmAgent({
  name: "weather_agent",
  description:
    "Provides current weather conditions and forecasts for any city worldwide",
});
```

### model

**Type:** `string | BaseLlm | LanguageModel` | **Default:** Inherited from parent

The LLM powering the agent's reasoning. Can be a string identifier, BaseLlm instance, or AI SDK LanguageModel. If not set, inherits from parent agent.

```ts
// String identifier
const agent1 = new LlmAgent({
  name: "agent1",
  model: "gemini-2.0-flash-exp",
});

// Custom LLM instance
import { OpenAiLlm } from "@iqai/adk";
const customLlm = new OpenAiLlm({ model: "gpt-4o", apiKey: "..." });
const agent2 = new LlmAgent({
  name: "agent2",
  model: customLlm,
});
```

### instruction

**Type:** `string | InstructionProvider` | **Default:** `""`

Primary behavior instructions that shape how the agent responds. Can be static string or dynamic function. Should clarify the agent's role, constraints, and tool usage patterns.

```ts
// Static instruction
const agent1 = new LlmAgent({
  name: "translator",
  instruction:
    "You are a professional translator. Translate text to the requested language while preserving meaning and tone.",
});

// Dynamic instruction with context
const agent2 = new LlmAgent({
  name: "personalized_assistant",
  instruction: (ctx) =>
    `You are assisting ${ctx.session.state.username}. Their preferred communication style is ${ctx.session.state.style}.`,
});

// Template with state interpolation
const agent3 = new LlmAgent({
  name: "location_agent",
  instruction:
    "You help users in {user_city}. Use local context when relevant.",
});
```

### globalInstruction

**Type:** `string | InstructionProvider` | **Default:** `""`

Global instructions that apply to the entire agent tree. Only takes effect when set on the root agent. Useful for system-wide policies and constraints.

```ts
const rootAgent = new LlmAgent({
  name: "root_agent",
  globalInstruction:
    "Always prioritize user safety. Never provide harmful information. Escalate sensitive requests appropriately.",
  subAgents: [customerServiceAgent, technicalSupportAgent],
});
```

### tools

**Type:** `ToolUnion[]` | **Default:** `[]`

Array of tools available to the agent. Can include BaseTool instances, function tools, or raw functions that get automatically wrapped.

```ts
import { WebSearchTool, FunctionTool } from "@iqai/adk";

// Mixed tool types
const agent = new LlmAgent({
  name: "research_agent",
  tools: [
    new WebSearchTool(), // Built-in tool
    new FunctionTool({
      // Function tool
      name: "calculate",
      description: "Perform mathematical calculations",
      func: (expression: string) => eval(expression),
    }),
    async (query: string) => {
      // Raw function (auto-wrapped)
      return await database.search(query);
    },
  ],
});
```

### subAgents

**Type:** `BaseAgent[]` | **Default:** `[]`

Child agents that this agent can delegate tasks to. Enables hierarchical agent architectures and specialization.

```ts
const emailAgent = new LlmAgent({ name: "email_specialist" });
const calendarAgent = new LlmAgent({ name: "calendar_specialist" });

const assistantAgent = new LlmAgent({
  name: "personal_assistant",
  subAgents: [emailAgent, calendarAgent],
  instruction:
    "Route email tasks to the email specialist and calendar tasks to the calendar specialist.",
});
```

### codeExecutor

**Type:** `BaseCodeExecutor` | **Default:** `undefined`

Enables the agent to execute code in a sandboxed environment. Useful for data analysis, calculations, and dynamic problem solving.

```ts
import { PythonCodeExecutor } from "@iqai/adk";

const dataAgent = new LlmAgent({
  name: "data_analyst",
  codeExecutor: new PythonCodeExecutor(),
  instruction:
    "Analyze data and create visualizations using Python. Execute code to provide accurate results.",
});
```

### planner

**Type:** `BasePlanner` | **Default:** `undefined`

Strategic planning capability that enables the agent to break down complex tasks into steps and execute them systematically.

```ts
import { PlanReActPlanner } from "@iqai/adk";

const projectAgent = new LlmAgent({
  name: "project_manager",
  planner: new PlanReActPlanner(),
  instruction:
    "Break down complex projects into actionable steps and execute them systematically.",
});
```

### memoryService

**Type:** `BaseMemoryService` | **Default:** `undefined`

Long-term memory storage for persistent information across sessions. Enables agents to remember facts, preferences, and context.

```ts
import { VectorMemoryService } from "@iqai/adk";

const agent = new LlmAgent({
  name: "knowledge_agent",
  memoryService: new VectorMemoryService({
    apiKey: process.env.OPENAI_API_KEY,
  }),
  instruction:
    "Remember important facts about users and reference them in future conversations.",
});
```

### sessionService

**Type:** `BaseSessionService` | **Default:** `undefined`

Manages conversation state and history. Usually handled automatically by AgentBuilder, but can be customized for specific session management needs.

```ts
import { InMemorySessionService } from "@iqai/adk";

const agent = new LlmAgent({
  name: "chat_agent",
  sessionService: new InMemorySessionService(),
});
```

### artifactService

**Type:** `BaseArtifactService` | **Default:** `undefined`

File storage and management service for handling documents, images, and other artifacts during conversations.

```ts
import { LocalArtifactService } from "@iqai/adk";

const agent = new LlmAgent({
  name: "document_agent",
  artifactService: new LocalArtifactService({ baseDir: "./uploads" }),
  instruction:
    "Help users manage and analyze documents. Save important files for future reference.",
});
```

### includeContents

**Type:** `"default" | "none"` | **Default:** `"default"`

Controls whether conversation history is included in model requests. Use `"none"` for stateless agents or privacy-sensitive scenarios.

```ts
// Stateless agent (no conversation history)
const statelessAgent = new LlmAgent({
  name: "calculator",
  includeContents: "none",
  instruction: "Perform calculations without needing conversation context.",
});

// Stateful agent (includes history)
const chatAgent = new LlmAgent({
  name: "assistant",
  includeContents: "default", // Default behavior
});
```

### outputKey

**Type:** `string` | **Default:** `undefined`

Session state key where the agent's output will be stored. Enables other agents to access this agent's results.

```ts
const analysisAgent = new LlmAgent({
  name: "data_analyzer",
  outputKey: "analysis_results",
  instruction:
    "Analyze the provided data and store results for other agents to use.",
});

// Later, another agent can access: ctx.session.state.analysis_results
```

### inputSchema & outputSchema

**Type:** `ZodSchema` | **Default:** `undefined`

Zod schemas for input validation and structured output. When outputSchema is set, the agent can only reply and cannot use tools.

```ts
import { z } from "zod";

const InputSchema = z.object({
  text: z.string(),
  language: z.string(),
});

const OutputSchema = z.object({
  translation: z.string(),
  confidence: z.number(),
});

const translatorAgent = new LlmAgent({
  name: "translator",
  inputSchema: InputSchema,
  outputSchema: OutputSchema, // Disables tool usage
  instruction: "Translate text and provide confidence score.",
});
```

### generateContentConfig

**Type:** `GenerateContentConfig` | **Default:** `undefined`

Fine-tune LLM generation parameters like temperature, max tokens, and safety settings.

```ts
const creativeAgent = new LlmAgent({
  name: "creative_writer",
  generateContentConfig: {
    temperature: 0.9, // High creativity
    maxOutputTokens: 1000, // Longer responses
    topP: 0.95, // Nucleus sampling
    topK: 40, // Top-k sampling
  },
});

const preciseAgent = new LlmAgent({
  name: "fact_checker",
  generateContentConfig: {
    temperature: 0.1, // Low creativity, high precision
    maxOutputTokens: 200, // Concise responses
  },
});
```

### Transfer Control Options

**Type:** `boolean` | **Default:** `false`

Control whether the agent can transfer to parent or peer agents via LLM decision-making.

```ts
const restrictedAgent = new LlmAgent({
  name: "secure_agent",
  disallowTransferToParent: true, // Cannot escalate
  disallowTransferToPeers: true, // Cannot delegate to siblings
  instruction:
    "Handle all requests independently without transferring control.",
});
```

### Session Identifiers

**Type:** `string` | **Default:** `undefined`

User and application identifiers for session management and analytics.

```ts
const agent = new LlmAgent({
  name: "user_agent",
  userId: "user_12345",
  appName: "my_assistant_app",
});
```

### Callback Hooks

**Type:** Various callback types | **Default:** `undefined`

Hooks for monitoring and controlling agent execution at different stages.

```ts
const monitoredAgent = new LlmAgent({
  name: "monitored_agent",
  beforeAgentCallback: (ctx) => {
    console.log(`Starting agent: ${ctx.agent.name}`);
    // Return content to skip agent execution, or undefined to continue
  },
  afterAgentCallback: (ctx) => {
    console.log(`Completed agent: ${ctx.agent.name}`);
  },
  beforeModelCallback: (ctx, request) => {
    console.log("Calling LLM with:", request.parts);
    // Return LlmResponse to skip model call, or null to continue
  },
  afterModelCallback: (ctx, response) => {
    console.log("LLM responded:", response.content);
  },
  beforeToolCallback: (tool, args, ctx) => {
    console.log(`Calling tool: ${tool.name}`);
    // Return modified args or null to continue with original
  },
  afterToolCallback: (tool, args, ctx, response) => {
    console.log(`Tool ${tool.name} returned:`, response);
  },
});
```

## Complete Configuration Example

Here's a comprehensive example showing an LLM agent with all major configuration options:

```ts
import {
  LlmAgent,
  FunctionTool,
  WebSearchTool,
  PythonCodeExecutor,
  PlanReActPlanner,
  VectorMemoryService,
  LocalArtifactService,
} from "@iqai/adk";
import { z } from "zod";

// Define schemas
const InputSchema = z.object({
  query: z.string(),
  priority: z.enum(["low", "medium", "high"]),
});

const OutputSchema = z.object({
  response: z.string(),
  confidence: z.number(),
  sources: z.array(z.string()),
});

// Define tools
const searchDatabase = async (query: string) => {
  // Custom database search logic
  return { results: ["result1", "result2"], count: 2 };
};

const calculateMetrics = (data: number[]) => {
  const sum = data.reduce((a, b) => a + b, 0);
  return { sum, average: sum / data.length, count: data.length };
};

// Create sub-agents
const researchAgent = new LlmAgent({
  name: "research_specialist",
  model: "gemini-2.0-flash-exp",
  description: "Specializes in data research and analysis",
  tools: [new WebSearchTool()],
});

const analysisAgent = new LlmAgent({
  name: "analysis_specialist",
  model: "gemini-2.0-flash-exp",
  description: "Performs statistical analysis and calculations",
  codeExecutor: new PythonCodeExecutor(),
});

// Main agent with comprehensive configuration
const comprehensiveAgent = new LlmAgent({
  // === REQUIRED OPTIONS ===
  name: "advanced_assistant",

  // === IDENTITY & BASIC CONFIG ===
  description:
    "Advanced AI assistant with research, analysis, and planning capabilities",
  model: "gemini-2.0-flash-exp",

  // === INSTRUCTIONS ===
  instruction: (ctx) => `
    You are an advanced AI assistant helping ${
      ctx.session.state.username || "the user"
    }.
    
    **Your capabilities:**
    - Research information using web search and database tools
    - Perform data analysis and statistical calculations  
    - Create and execute plans for complex tasks
    - Remember important information across conversations
    - Generate structured outputs with confidence scores
    
    **Guidelines:**
    - Always provide sources for factual claims
    - Use sub-agents for specialized tasks (research_specialist, analysis_specialist)
    - Execute code for accurate calculations
    - Store important findings in memory for future reference
    - Be thorough but concise in responses
  `,

  globalInstruction:
    "Always prioritize accuracy and user safety. Verify information before presenting it as fact.",

  // === TOOLS & CAPABILITIES ===
  tools: [
    FunctionTool.fromFunction(
      searchDatabase,
      "Search internal database for relevant information"
    ),
    FunctionTool.fromFunction(
      calculateMetrics,
      "Calculate statistical metrics from numerical data"
    ),
    new WebSearchTool(),
  ],

  subAgents: [researchAgent, analysisAgent],

  // === ADVANCED FEATURES ===
  codeExecutor: new PythonCodeExecutor(),
  planner: new PlanReActPlanner(),
  memoryService: new VectorMemoryService({
    apiKey: process.env.OPENAI_API_KEY,
  }),
  artifactService: new LocalArtifactService({
    baseDir: "./user_files",
  }),

  // === SCHEMA VALIDATION ===
  inputSchema: InputSchema,
  outputSchema: OutputSchema,

  // === GENERATION CONTROL ===
  generateContentConfig: {
    temperature: 0.3, // Balanced creativity
    maxOutputTokens: 1500, // Detailed responses
    topP: 0.95,
    topK: 40,
  },

  // === CONTEXT & STATE MANAGEMENT ===
  includeContents: "default",
  outputKey: "assistant_response",
  disallowTransferToParent: false,
  disallowTransferToPeers: false,

  // === SESSION MANAGEMENT ===
  userId: "user_12345",
  appName: "advanced_assistant_app",

  // === CALLBACK HOOKS ===
  beforeAgentCallback: (ctx) => {
    console.log(
      `[${new Date().toISOString()}] Starting agent: ${ctx.agent.name}`
    );
    // Could return content to skip agent execution
  },

  afterAgentCallback: (ctx) => {
    console.log(
      `[${new Date().toISOString()}] Completed agent: ${ctx.agent.name}`
    );
    // Could return modified content
  },

  beforeModelCallback: (ctx, request) => {
    console.log(`Calling LLM with ${request.parts.length} message parts`);
    // Could return LlmResponse to skip model call
    return null; // Continue with original request
  },

  afterModelCallback: (ctx, response) => {
    console.log(
      `LLM response length: ${
        response.content.parts[0]?.text?.length || 0
      } characters`
    );
    // Could return modified response
    return null; // Use original response
  },

  beforeToolCallback: (tool, args, ctx) => {
    console.log(`Executing tool: ${tool.name}`);
    // Could return modified args
    return null; // Use original args
  },

  afterToolCallback: (tool, args, ctx, response) => {
    console.log(`Tool ${tool.name} completed successfully`);
    // Could return modified response
    return null; // Use original response
  },
});

// Usage example with AgentBuilder
const { agent, runner } = await AgentBuilder.withAgent(
  comprehensiveAgent
).build();

// Structured input matching schema
const response = await runner.ask({
  query: "What are the latest developments in renewable energy?",
  priority: "high",
});

// Response will match OutputSchema format:
// {
//   response: "Based on recent research...",
//   confidence: 0.95,
//   sources: ["https://example.com/article1", "research_database_entry_123"]
// }
```

This comprehensive example demonstrates:

- **All configuration options** with clear organization by category
- **Structured I/O** with Zod schemas for validation
- **Multi-modal capabilities** combining tools, sub-agents, code execution, and planning
- **Production features** like memory, artifacts, and comprehensive logging
- **Callback integration** for monitoring, analytics, and custom processing
- **Dynamic instructions** that adapt to user context
- **Hierarchical architecture** with specialized sub-agents

<Callout type="warn" title="Important Notes">
  - When `outputSchema` is set, the agent **cannot use tools**, it can only
  generate structured responses - Callbacks should return `null` or `undefined`
  to continue with original behavior - The `model` field inherits from parent
  agents if not explicitly set - Global instructions only take effect when set
  on the **root agent**
</Callout>

## Related Topics

<Cards>
  <Card
    title="ðŸ¤– Models & Providers"
    description="Configure LLM models, providers, and generation settings"
    href="/docs/framework/agents/models"
  />
  <Card
    title="ðŸ› ï¸ Tools"
    description="Available tools, agent tools, and how to create custom tools"
    href="/docs/framework/tools"
  />
  <Card
    title="ðŸ§  Sessions & Memory"
    description="Manage conversation state, memory, and session persistence"
    href="/docs/framework/sessions"
  />
  <Card
    title="ðŸ‘¥ Multi-Agent Systems"
    description="Coordinate agents, delegate tasks, and use system-wide instructions"
    href="/docs/framework/agents/multi-agents"
  />
  <Card
    title="ðŸ“‹ Callbacks"
    description="Hook into agent execution for monitoring and control"
    href="/docs/framework/callbacks"
  />
  <Card
    title="ðŸ”§ Agent Builder"
    description="Fluent API for rapid agent creation and configuration"
    href="/docs/framework/agents/agent-builder"
  />
</Cards>
