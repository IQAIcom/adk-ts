---
title: Agent Evaluation
description: Comprehensive framework for testing and validating agent performance across scenarios
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';

Agent evaluation provides systematic approaches to testing and validating agent performance, moving beyond prototype to production-ready AI systems.

<Callout type="info" title="Experimental Framework">
The comprehensive evaluation framework is now available in `@iqai/adk` as an experimental feature. APIs may change as we gather feedback and refine the system.
</Callout>

## Overview

Unlike traditional software testing, agent evaluation must account for the probabilistic nature of LLM responses and the complexity of multi-step reasoning processes. Effective evaluation encompasses multiple dimensions from tool usage patterns to response quality.

## Key Features

The ADK evaluation framework provides comprehensive agent testing capabilities:

- **Agent Evaluator**: Automated evaluation of agent performance across test cases
- **Multiple Metrics**: ROUGE scoring, LLM-as-judge, tool trajectory analysis, safety evaluation
- **Flexible Test Format**: JSON-based test cases with support for multi-turn conversations
- **Local & Cloud Evaluation**: Run evaluations locally or integrate with Vertex AI
- **Session State Support**: Test stateful agents with conversation history
- **Configurable Thresholds**: Set pass/fail criteria for different evaluation metrics

## Documentation Structure

<Cards>
  <Card
    title="ðŸ“‹ Evaluation Concepts"
    description="Core principles and challenges in agent evaluation"
    href="/docs/framework/evaluation/evaluation-concepts"
  />

  <Card
    title="ðŸ§ª Testing Agents"
    description="Current approaches and future automated testing methods"
    href="/docs/framework/evaluation/testing-agents"
  />

  <Card
    title="ðŸ“Š Metrics and Scoring"
    description="Measurement approaches for trajectory and response quality"
    href="/docs/framework/evaluation/metrics-and-scoring"
  />

  <Card
    title="ðŸŽ¯ Evaluation Patterns"
    description="Domain-specific evaluation strategies and best practices"
    href="/docs/framework/evaluation/evaluation-patterns"
  />
</Cards>

## Core Components

The evaluation framework includes these key components:

- **AgentEvaluator**: Main entry point for agent performance assessment
- **TrajectoryEvaluator**: Analyzes tool usage patterns and decision paths
- **ResponseEvaluator**: ROUGE-1 scoring and LLM-based response quality assessment
- **SafetyEvaluator**: Evaluates response harmlessness and safety
- **EvalSet Management**: Organized test cases with metadata and version control
- **MetricEvaluatorRegistry**: Extensible system for custom evaluation metrics
- **LocalEvalService**: Complete local evaluation pipeline with parallel execution

## Getting Started

To begin using the evaluation framework:

1. **Create Test Cases**: Define evaluation scenarios in JSON format with expected outputs
2. **Configure Metrics**: Set up evaluation criteria and thresholds in `test_config.json`
3. **Run Evaluations**: Use `AgentEvaluator.evaluate()` to assess agent performance
4. **Analyze Results**: Review detailed evaluation results with per-metric scoring

```typescript
import { AgentEvaluator } from '@iqai/adk/evaluation';

// Evaluate agent against test files
const results = await AgentEvaluator.evaluate({
  agent,
  testFilePaths: ['./tests/basic.test.json'],
  testConfigFilePath: './test_config.json'
});

console.log(`Overall Score: ${results.overallScore}`);
```

## Related Topics

<Cards>
  <Card
    title="ðŸ¤– Agents"
    description="Learn about different agent types and their capabilities"
    href="/docs/framework/agents"
  />

  <Card
    title="ðŸ”§ Tools"
    description="Understand tool integration and usage patterns"
    href="/docs/framework/tools"
  />

  <Card
    title="ðŸ’¬ Sessions"
    description="Session management for conversation tracking"
    href="/docs/framework/sessions"
  />

  <Card
    title="ðŸ“‹ Callbacks"
    description="Event handling and agent lifecycle management"
    href="/docs/framework/callbacks"
  />
</Cards>