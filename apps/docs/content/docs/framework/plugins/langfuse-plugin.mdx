---
title: Langfuse Plugin
description: Capture, track, and analyze agent and tool interactions with Langfuse in @iqai/adk
---

# Langfuse Plugin

The **Langfuse Plugin** integrates `@iqai/adk` agents with **[Langfuse](https://langfuse.com/docs)** for robust tracing, monitoring, and observability of LLM and tool executions. It automatically records user messages, agent actions, model generations, and tool calls, including errors and token usage.

This plugin is especially useful for:

- Observability of agent workflows
- Debugging tool or model errors
- Tracking model usage and token consumption
- Correlating events across complex agent hierarchies


## Key Features

- **Automatic tracing**: Tracks every invocation, agent, tool, and model generation.
- **Error monitoring**: Captures LLM or tool errors with full context.
- **Token and model usage tracking**: Aggregates input/output tokens and models used per invocation.
- **Hierarchical spans**: Supports nested agents and tool calls with parent-child relationships.
- **Flexible serialization**: Converts complex `Content` and `Event` objects into structured logs for Langfuse.
- **Flush and shutdown control**: Manually flush or shutdown Langfuse client if needed.


## Installation

```bash
pnpm add @iqai/adk langfuse
```


## Setup and Usage

You can attach the plugin to your agent using `AgentBuilder` or directly with `LlmAgent`.

### Using AgentBuilder (recommended)

```ts
import { AgentBuilder, InMemorySessionService } from "@iqai/adk";
import { LangfusePlugin } from "./langfuse-plugin";
import { openrouter } from "@iqai/adk/models";
import { randomUUID } from "crypto";

const langfusePlugin = new LangfusePlugin({
  publicKey: process.env.LANGFUSE_PUBLIC_KEY!,
  secretKey: process.env.LANGFUSE_SECRET_KEY!,
  flushAt: 5,
});

const sessionService = new InMemorySessionService();

const { runner } = await AgentBuilder.withModel(
  openrouter("openai/gpt-4.1-mini"),
)
  .withDescription("Calendar scheduling assistant")
  .withInstruction("Help users manage calendar events.")
  .withTools(/* calendar tools */)
  .withSessionService(sessionService)
  .withQuickSession({
    sessionId: randomUUID(),
    appName: "calendar-agent",
  })
  .withPlugins(langfusePlugin)
  .build();
```

### Using LlmAgent directly

```ts
import { LlmAgent } from "@iqai/adk";
import { LangfusePlugin } from "./langfuse-plugin";

const agent = new LlmAgent({
  name: "calendar_specialist",
  description: "Agent for calendar scheduling",
  plugins: [
    new LangfusePlugin({
      publicKey: process.env.LANGFUSE_PUBLIC_KEY!,
      secretKey: process.env.LANGFUSE_SECRET_KEY!,
    }),
  ],
});
```


## Configuration Options

| Option          | Type   | Default                           | Description                     |
| --------------- | ------ | --------------------------------- | ------------------------------- |
| `name`          | string | `"langfuse_plugin"`               | Plugin name for identification  |
| `publicKey`     | string | -                                 | Langfuse public API key         |
| `secretKey`     | string | -                                 | Langfuse secret API key         |
| `baseUrl`       | string | `"https://us.cloud.langfuse.com"` | Langfuse API endpoint           |
| `release`       | string | undefined                         | Optional release tag for traces |
| `flushAt`       | number | `1`                               | Flush after this many events    |
| `flushInterval` | number | `1000`                            | Flush interval in milliseconds  |


## Callback Hooks

The plugin intercepts key agent events to send structured logs to Langfuse:

### User messages

* **`onUserMessageCallback`**: Records user input and triggers a `user_message` event.

### Agent execution

* **`beforeAgentCallback` / `afterAgentCallback`**: Starts and ends agent spans. Tracks input, output, models used, and sub-agent hierarchy.

### Model calls

* **`beforeModelCallback` / `afterModelCallback`**: Captures model request and response, including token usage and generation metadata.
* **`onModelErrorCallback`**: Logs errors for LLM calls with full context.

### Tool calls

* **`beforeToolCallback` / `afterToolCallback`**: Captures tool invocation and results.
* **`onToolErrorCallback`**: Records tool failures and metadata.

### Run lifecycle

* **`beforeRunCallback` / `afterRunCallback`**: Tracks overall invocation start and completion.
* **`onEventCallback`**: Captures all events in the invocation, including function calls and final outputs.


## Advanced Usage

### Customizing serialization

`LangfusePlugin` converts complex `Content` or `Event` objects to structured logs. You can extend:

```ts
class CustomLangfusePlugin extends LangfusePlugin {
  protected toPlainText(data: any): string {
    // Custom logic to extract plain text
    return super.toPlainText(data);
  }
}
```

### Manual flush and shutdown

```ts
await langfusePlugin.flush();
await langfusePlugin.close();
```


## Benefits

* Centralized observability for multi-agent workflows
* Debugging complex tool and LLM interactions
* Token and model usage analytics
* Error tracking with detailed context
* Supports nested agents and tool spans
